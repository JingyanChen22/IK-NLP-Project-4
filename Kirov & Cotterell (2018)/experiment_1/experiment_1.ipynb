{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"experiment_1.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1Qp0vrnT3Sz_M_yA-E1CEE1WjMQLq_Kt_","authorship_tag":"ABX9TyN1cBOUBBHELXzZp0MZtnwp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# install the package\n","!pip install OpenNMT-py"],"metadata":{"id":"-8j4MQ0giWY1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import codecs\n","import pickle as cPickle\n","import random\n","from collections import defaultdict\n","import pandas as pd"],"metadata":{"id":"0Lu_rN_zUkVZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def createDatasets(corpus_file,sequence=\"grapheme\"):\n","  \"\"\"\n","  generate train, valid, test sets\n","  \"\"\"\n","  #read in data\n","  fin = codecs.open(corpus_file,'rb','utf-8')\n","\n","  sources = []\n","  targets = []\n","\n","  for line in fin:\n","    parts = line.strip().split()\n","    if sequence == \"grapheme\":\n","      lemma = parts[0]\n","      form = parts[1]\n","      sources.append(' '.join(lemma))\n","      targets.append(' '.join(form))\n","    elif sequence == \"phoneme\":\n","      lemma = parts[2]\n","      form = parts[3]\n","      sources.append(' '.join(lemma))\n","      targets.append(' '.join(form))\n","    else:\n","      print(\"Input the correct sequence type.\")\n","  fin.close()\n","\n","  pairs = list(zip(sources,targets))\n","  random.shuffle(pairs)\n","\n","  #split into train, valid and test (8-1-1)\n","  train = pairs[:int(.8*len(pairs))]\n","  valid = pairs[int(.8*len(pairs)):int(.9*len(pairs))]\n","  test = pairs[int(.9*len(pairs)):]\n","\n","  #set up output file\n","  fout_src_train = codecs.open('/data/src_train.txt','wb','utf-8')\n","  fout_tgt_train = codecs.open('/data/tgt_train.txt','wb','utf-8')\n","  fout_src_valid = codecs.open('/data/src_valid.txt','wb','utf-8')\n","  fout_tgt_valid = codecs.open('/data/tgt_valid.txt','wb','utf-8')\n","  fout_src_test = codecs.open('/data/src_test.txt','wb','utf-8')\n","  fout_tgt_test = codecs.open('/data/tgt_test.txt','wb','utf-8')\n","\n","  #write the outputs\n","  for s,t in train:\n","    fout_src_train.write(s + '\\n')\n","    fout_tgt_train.write(t + '\\n')\n","\n","  for s,t in valid:\n","    fout_src_valid.write(s + '\\n')\n","    fout_tgt_valid.write(t + '\\n')\n","\n","  for s,t in test:\n","    fout_src_test.write(s + '\\n')\n","    fout_tgt_test.write(t + '\\n')\n","\n","  \n","\n","  fout_src_train.close()\n","  fout_tgt_train.close()\n","  fout_src_valid.close()\n","  fout_tgt_valid.close()\n","  fout_src_test.close()\n","  fout_tgt_test.close()"],"metadata":{"id":"BoeEuFAVvKcb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def DataFrame_merged(merged_file):\n","  \"\"\"\n","  read the merged file and convert it to a dataframe, and get some basic information about it.\n","  \"\"\"\n","\n","  data = pd.read_csv(merged_file,sep='\\t',names=[\"pre_tense\",\"past_tense\",\"IPA_pre\",\"IPA_past\",\"label\"])\n","  print(data[:5])\n","\n","  print(\"number of regular verbs:\", len(data.loc[data[\"label\"]==\"reg\"]))\n","  print(\"number of irregular verbs:\", len(data.loc[data[\"label\"]==\"irreg\"]))\n","  return data\n","  \n","def DataFrame_file(filename):\n","  \"\"\"\n","  read the file and convert it to a dataframe\n","  \"\"\"\n","  with open(filename,'r') as f:\n","      list_file = [line.strip('\\n').replace(\" \",\"\") for line in f]\n","  return pd.DataFrame(list_file)"],"metadata":{"id":"CkcfyFtKUag-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluation(file_tgt,file_pre,file_src,sequence=\"grapheme\"):\n","  '''\n","  calculate the accuracy of regular and irregular verbs in the set and the accuracy of the set, \n","  and return them\n","  '''\n","  df_pre = DataFrame_file(file_pre)\n","  df_tgt = DataFrame_file(file_tgt)\n","  df_src = DataFrame_file(file_src)\n","  df_set = pd.concat([df_pre,df_tgt,df_src],axis=1)\n","\n","  if sequence == \"grapheme\":\n","    df_set.columns = [\"prediction\",\"past_tense\",\"pre_tense\"]\n","    df_set_merged = pd.merge(data, df_set)\n","    df_set_wrong = df_set_merged.loc[df_set_merged[\"prediction\"]!=df_set_merged[\"past_tense\"]]\n","  else:\n","    df_set.columns = [\"prediction\",\"IPA_past\",\"IPA_pre\"]\n","    df_set_merged = pd.merge(data, df_set)\n","    df_set_wrong = df_set_merged.loc[df_set_merged[\"prediction\"]!=df_set_merged[\"IPA_past\"]]\n","\n","  total_reg = len(df_set_merged.loc[df_set_merged[\"label\"]==\"reg\"])\n","  total_ir = len(df_set_merged.loc[df_set_merged[\"label\"]==\"irreg\"])\n","  wrong_reg = len(df_set_wrong.loc[df_set_wrong[\"label\"]==\"reg\"])\n","  wrong_ir = len(df_set_wrong.loc[df_set_wrong[\"label\"]==\"irreg\"])\n","\n","  print(\"Set\\tRegular\\tIrregular\\n\"+\"-\"*40)\n","  print(f\"{round(1-len(df_set_wrong)/len(df_set),4)}\\t\"\n","    f\"{round(1-wrong_reg/total_reg,4)}\\t\"\n","    f\"{round(1-wrong_ir/total_ir,4)}\"\n","    )"],"metadata":{"id":"KvOfVaZsUdHJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!onmt_build_vocab -config /experiment_1/config.yaml -n_sample 16200\n","!onmt_train -config /experiment_1/config.yaml"],"metadata":{"id":"R5QbpMPilihh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!onmt_translate -model /experiment_1/run/model_step_16200.pt -src /experiment_1/src_train.txt -output experiment_1/pre_train.txt\n","!onmt_translate -model /experiment_1/run/model_step_16200.pt -src /experiment_1/src_valid.txt -output experiment_1/pre_valid.txt\n","!onmt_translate -model /experiment_1/run/model_step_16200.pt -src /experiment_1/src_test.txt -output experiment_1/pre_test.txt"],"metadata":{"id":"iCzYuj0PmIPC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["merged_file = \"experiment_1/english_merged.txt\"\n","\n","tgt_train = \"experiment_1/tgt_train.txt\"\n","pre_train = \"experiment_1/pre_train.txt\"\n","src_train = \"experiment_1/src_train.txt\"\n","print(\"train set:\")\n","evaluation(tgt_train,pre_train,src_train)\n","\n","tgt_valid = \"experiment_1/tgt_valid.txt\"\n","pre_valid = \"experiment_1/pre_valid.txt\"\n","src_valid = \"experiment_1/src_valid.txt\"\n","print(\"valid set:\")\n","evaluation(tgt_valid,pre_valid,src_valid)\n","\n","tgt_test = \"experiment_1/tgt_test.txt\"\n","pre_test = \"experiment_1/pre_test.txt\"\n","src_test = \"experiment_1/src_test.txt\"\n","print(\"test set:\")\n","evaluation(tgt_test,pre_test,src_test)"],"metadata":{"id":"YFcwSuIHjM9N"},"execution_count":null,"outputs":[]}]}